<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
	<header name = "Access-Control-Allow-Origin" value = "*" /> 
    <title>Music</title>
    <!--    引入外部css文件-->
    <link href="favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="css/music.css">

</head>

<style>
      #file {
          position: fixed;
          top: 10px;
          left: 10px;
          z-index: 100;
      }
      
      #canvas {
          position: fixed;
          left: 0;
          top: 0;
          width: 100%;
          height: 100%;
		  opacity: 0.5;
      }
</style>
<body>
<div class="m_body">

<div id="content">

</div>

    <!--横幅-->
	<div class="bannerbg">
	<div class="downdemos">
 <a id="downdemosa"  target="_blank" href="https://pan.baidu.com/s/1yZfyG9s2xNSHD3sqrqCeWQ?pwd=ljrp"  title="download test set"  >download test set</a></div>
    <div class="banner">
	   <!-- <canvas id="canvas"></canvas>
	   分别为 Noisy, GaGNet, DCCRN, MetricGAN+, DB-AIAT, SE-LMA-Transformer
	  -->
	
        <ul>
            <li id="m1" class="m1" datasrc="ListeningDemos/p232_343/noisy_demo_1_p257_135.wav" title="p232_005">
                <img src="img/1.jpg" alt=""width="65">demo1
            </li>
            <li class="m2" datasrc="ListeningDemos/p232_409/noisy_demo_2_p232_409.wav" title="p232_095">
                <img src="img/2.jpg" alt=""width="90">demo2
            </li>
            <li class="m3" datasrc="ListeningDemos/p257_013/noisy_demo_3_p257_013.wav" title="p232_113">
                <img src="img/3.jpg" alt=""width="119">demo3
            </li>
            <li class="m4" datasrc="ListeningDemos/p257_069/noisy_demo_4_p257_069.wav" title="p232_242">
                <img src="img/4.jpg" alt=""width="90">demo4
            </li>
            <li class="m5" datasrc="ListeningDemos/p257_130/noisy_demo_5_p257_130.wav" title="p232_343">
                <img src="img/5.jpg" alt=""width="65">demo5
            </li>
			<li class="m6" datasrc="ListeningDemos/p257_135/noisy_demo_6_p257_135.wav" title="p257_013">
                <img src="img/6.jpg" alt=""width="65">demo6
            </li>
        </ul>
    </div>
    </div>
	<!--横幅-->
		<div class="model">
		 <a href="#" class="m_model model_hover" title="noisy"  data-title="">Noisy</a>
		<a href="#" class="m_model" title="dccrn" data-title="">DCCRN</a>
		 <a href="#" class="m_model" title="gagnet" data-title="">GaGNet</a>

		 <a href="#" class="m_model" title="metricgan" data-title="">MetricGAN+</a>
		 <!--<a href="#" class="m_model" title="db-aiat" data-title="">DB-AIAT</a>-->
		  <a href="#" class="m_model" title="se-lmr-trans" data-title="">SE-LMA-Transformer</a>
		 
		 
		 <div class="m_info" >SE-LMA-Transformer<br>

Abstract
Time-frequency analysis in single-channel speech enhancement has received considerable attention. While Transformer-based architectures are gaining traction, their computational burden can be substantial, especially when dealing with longer speech samples. To address this, our research introduces the lightweight multi-axial Transformer (LMA-Transformer) optimized for low computational overhead while efficiently extracting features along both temporal and frequency axes. Central to our approach is the Temporal/Frequency Multi-DConv head self-attention module (T/F-MDHSA), which not only reduces computational costs but also improves the Transformer's capability to utilize local features effectively. Moreover, we introduce the frequency prompt block, designed to dynamically guide the recovery of frequency features in speech signals that have experienced varying levels of degradation. Compared to state-of-the-art models, our model has competitive performance with 3.40 PESQ, 95.8% STOI, and 10.15 SSNR on the VoiceBank + Demand dataset. <br>
<br>

Key References:
Y.Hu, Y. Liu, S. Lv, M. Xing, S. Zhang, Y. Fu, J. Wu, B. Zhang, and L. Xie, “DCCRN: Deep complex convolution recurrent network for phase-aware speech enhancement,” in INTERSPEECH, 2020, pp. 2472–2476.<br>
<br>

D. Yin, C. Luo, Z. Xiong, and W. Zeng, “Phasen: A phaseand-harmonics-aware speech enhancement network,” in AAAI, 2020, p. 9458–9465.<br>
<br>

A. Li, C. Zheng, L. Zhang, and X. Li, “Glance and gaze: A collaborative learning framework for single-channel speech enhancement,” Applied Acoustics, vol. 187, pp.
108499, 2022.<br>
<br>

S. Fu, C. Yu, T. Hsieh, Plantinga P., M. Ravanelli, X. Lu, and Y. Tsao, “MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement,” in Interspeech,
2021, pp. 201–205.<br>
<br>

H. Shi, M. Mimura, L. Wang, J. Dang, and T. Kawahara, “Time-domain speech enhancement assisted by multiresolution frequency encoder and decoder,” in ICASSP,
2023, pp. 1–5
</div>

<div class="model_info">

		 </div>
	</div> <!--
<div class="m_textinfo">Param=-, MAC/S=- </div>
    <!--音乐播放器-->
    <div class="music">
        <div  class="m_img">
            <img id="playimg" src="img/1.jpg"width="90" alt="">
        </div>
        <div class="m_text">p232_005 - Noisy</div>
        <div class="m_btn">
            <a href="#" class="m_prev" title="上一首"></a>
            <a href="#" class="m_play" title="播放"></a>
            <a href="#" class="m_next" title="下一首"></a>
        </div>
        <div class="m_close"></div>
		<div id="paly_d"></div>
        <audio id="audio"src="SE-LMA-Transformer_ListeningDemos/Demo1/noisy-p232_005.wav" class="m_mp3" controls ></audio>
    </div>
    </div
    <!--音乐播放器-->
    
    <!-- 引入jQuery核心文件-->
    <script type="text/javascript" src="js/jquery-3.3.1.min.js"></script>
    <!--    引入外部js文件-->
    <script type="text/javascript" src="js/music.js"></script>
	
</body>
<script type="text/javascript">

window.onload = function () {
	//$("#m1").click();
	audio.pause();
	 audio.addEventListener('ended', function () {
		play.click();
    }, false);
};
</script>
</html>